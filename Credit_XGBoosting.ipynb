{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "from collections import OrderedDict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0.0\n",
       "1              0.0\n",
       "2              1.0\n",
       "3              1.0\n",
       "4              2.0\n",
       "            ...   \n",
       "284802    172786.0\n",
       "284803    172787.0\n",
       "284804    172788.0\n",
       "284805    172788.0\n",
       "284806    172792.0\n",
       "Name: Time, Length: 284807, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_amount = StandardScaler()\n",
    "scaler_time = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Amount\n",
    "\n",
    "scaled_amount = scaler_amount.fit_transform(df[['Amount']])\n",
    "list_amount = [item for sublist in scaled_amount.tolist() for item in sublist]\n",
    "scaled_amount = pd.Series(list_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Time\n",
    "\n",
    "scaled_time = scaler_time.fit_transform(df[['Time']])\n",
    "list_time = [item for sublist in scaled_time.tolist() for item in sublist]\n",
    "scaled_time = pd.Series(list_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, scaled_time.rename('Scaled_Time'), scaled_amount.rename('Scaled_Amount')], axis = 1)\n",
    "df.drop(['Time', 'Amount'], axis = 1, inplace = True)\n",
    "df = df.rename(columns={\"Scaled_Time\": \"Time\", \"Scaled_Amount\": \"Amount\"})\n",
    "df = df[['Time','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
    "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
    "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount','Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0 -1.996583 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1 -1.996583  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2 -1.996562 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3 -1.996562 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4 -1.996541 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4  0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Kurtosis is a measure of the combined sizes of the two tails. It measures the amount of probability in tails.\n",
    "    The value is often compared to the kurtosis of the normal distribution, which is equal to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Time           p-value:  0.000  skewness: -0.036  kurtosis: -1.294\n",
      "Variable: V1             p-value:  0.000  skewness: -3.281  kurtosis: 32.486\n",
      "Variable: V2             p-value:  0.000  skewness: -4.625  kurtosis: 95.771\n",
      "Variable: V3             p-value:  0.000  skewness: -2.240  kurtosis: 26.619\n",
      "Variable: V4             p-value:  0.000  skewness:  0.676  kurtosis:  2.635\n",
      "Variable: V5             p-value:  0.000  skewness: -2.426  kurtosis: 206.901\n",
      "Variable: V6             p-value:  0.000  skewness:  1.827  kurtosis: 42.642\n",
      "Variable: V7             p-value:  0.000  skewness:  2.554  kurtosis: 405.600\n",
      "Variable: V8             p-value:  0.063  skewness: -8.522  kurtosis: 220.583\n",
      "Variable: V9             p-value:  0.000  skewness:  0.555  kurtosis:  3.731\n",
      "Variable: V10            p-value:  0.000  skewness:  1.187  kurtosis: 31.988\n",
      "Variable: V11            p-value:  0.000  skewness:  0.357  kurtosis:  1.634\n",
      "Variable: V12            p-value:  0.000  skewness: -2.278  kurtosis: 20.241\n",
      "Variable: V13            p-value:  0.028  skewness:  0.065  kurtosis:  0.195\n",
      "Variable: V14            p-value:  0.000  skewness: -1.995  kurtosis: 23.879\n",
      "Variable: V15            p-value:  0.050  skewness: -0.308  kurtosis:  0.285\n",
      "Variable: V16            p-value:  0.000  skewness: -1.101  kurtosis: 10.419\n",
      "Variable: V17            p-value:  0.000  skewness: -3.845  kurtosis: 94.798\n",
      "Variable: V18            p-value:  0.000  skewness: -0.260  kurtosis:  2.578\n",
      "Variable: V19            p-value:  0.000  skewness:  0.109  kurtosis:  1.725\n",
      "Variable: V20            p-value:  0.000  skewness: -2.037  kurtosis: 271.011\n",
      "Variable: V21            p-value:  0.000  skewness:  3.593  kurtosis: 207.283\n",
      "Variable: V22            p-value:  0.835  skewness: -0.213  kurtosis:  2.833\n",
      "Variable: V23            p-value:  0.571  skewness: -5.875  kurtosis: 440.081\n",
      "Variable: V24            p-value:  0.000  skewness: -0.552  kurtosis:  0.619\n",
      "Variable: V25            p-value:  0.249  skewness: -0.416  kurtosis:  4.290\n",
      "Variable: V26            p-value:  0.015  skewness:  0.577  kurtosis:  0.919\n",
      "Variable: V27            p-value:  0.006  skewness: -1.170  kurtosis: 244.985\n",
      "Variable: V28            p-value:  0.002  skewness: 11.192  kurtosis: 933.381\n",
      "Variable: Amount         p-value:  0.004  skewness: 16.978  kurtosis: 845.078\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    col_name = df.columns[i]\n",
    "    t, p_val = stats.ttest_ind(df.loc[ df['Class']==0, col_name], df.loc[ df['Class']==1, col_name],equal_var=False)  \n",
    "    skewness = df.loc[:,col_name].skew()\n",
    "    kurtosis = stats.kurtosis(df.loc[:,col_name])\n",
    "    print('Variable: {:15s}'.format(col_name),end='')    \n",
    "    print('p-value: {:6.3f}  skewness: {:6.3f}  kurtosis: {:6.3f}'.format(p_val, skewness, kurtosis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    train 40%, validation 30%, test 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are interested in Class column\n",
    "\n",
    "Class = df['Class'].values\n",
    "Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling\n",
    "\n",
    "all_Ind = np.arange(len(Class))\n",
    "np.random.shuffle(all_Ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "\n",
    "# Numerical length\n",
    "\n",
    "numerical_Train = int(round(0.4 * len(Class)))\n",
    "numerical_Validation = int(round(0.3 * len(Class)))\n",
    "numerical_Test = len(Class) - numerical_Train - numerical_Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = all_Ind[:numerical_Train]\n",
    "Validation = all_Ind[numerical_Train:(numerical_Train+numerical_Validation)]\n",
    "Test =  all_Ind[(numerical_Train+numerical_Validation):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n",
    "\n",
    "train_X = df.iloc[Train,:30]\n",
    "validation_X = df.iloc[Validation,:30]\n",
    "test_X  = df.iloc[Test,:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y\n",
    "\n",
    "train_y = Class[Train]\n",
    "validation_y = Class[Validation]\n",
    "test_y = Class[Test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating matrices\n",
    "\n",
    "fixed_train = xgb.DMatrix(train_X, label = train_y)\n",
    "fixed_validation = xgb.DMatrix(validation_X, label = validation_y)\n",
    "fixed_test = xgb.DMatrix(test_X, label = test_y)\n",
    "\n",
    "# Fixed parameters\n",
    "\n",
    "number_of_rounds = 20 # number of boosting iterations\n",
    "\n",
    "parameters = {'silent':1,\n",
    "             'min_child_weight':1,\n",
    "             'objective':'binary:logistic',\n",
    "             'eval_metric':'auc',\n",
    "             'seed' : 1234}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparign the Variable Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    maximum tree depth: 5 steps, levels from 5 to 25\n",
    "    subsample: steps of 0.1, values from 0.5 to 1.0\n",
    "    colsample by tree: the same as in subsample\n",
    "    leaning rate: values from 0.01 to 0.4\n",
    "    minimum loss function: 5 steps, values from 0.00 to 0.2\n",
    "    relative weight of positive/negative: random small and big values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of negative to positive instances:  589.3\n",
      "Total number of combinations:            43200\n"
     ]
    }
   ],
   "source": [
    "# Ratio\n",
    "\n",
    "negative_to_positive = sum(train_y == 0) / sum(train_y == 1)\n",
    "print('Ratio of negative to positive instances: {:6.1f}'.format(negative_to_positive))\n",
    "\n",
    "# Parameters\n",
    "\n",
    "parameters_dict = OrderedDict()\n",
    "\n",
    "parameters_dict['max_depth'] = [5, 10, 15, 20, 25]\n",
    "parameters_dict['subsample'] =[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "parameters_dict['colsample_bytree'] = [0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "parameters_dict['eta'] = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "parameters_dict['gamma'] = [0.00, 0.05, 0.1, 0.15, 0.2]\n",
    "parameters_dict['scale_pos_weight'] = [30, 40, 50, 300, 400, 500, 600, 700]\n",
    "\n",
    "lengths = [len(lst) for lst in parameters_dict.values()]\n",
    "\n",
    "combinations = 1\n",
    "for i in range(len(lengths)):\n",
    "    combinations *= lengths[i]\n",
    "print('Total number of combinations: {:16d}'.format(combinations))  \n",
    "\n",
    "maximum_iterations = 100\n",
    "\n",
    "columns = [*parameters_dict.keys()] + ['F-Score','Best F-Score']\n",
    "\n",
    "# Saving the results\n",
    "\n",
    "results = pd.DataFrame(index = range(maximum_iterations), columns = columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance and Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    defining a function for performance measurement, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(predictions, labels, confusion_matrix = False):\n",
    "    \n",
    "    positive = sum(labels == 1)\n",
    "    negative = len(labels) - positive\n",
    "    \n",
    "    predicted_positive =sum(1 for i in range(len(predictions)) if (predictions[i]>=0.5))\n",
    "    predicted_negative =sum(1 for i in range(len(predictions)) if (predictions[i]>=0.5) & (labels[i]==1))\n",
    "    \n",
    "    false_positive = predicted_positive - predicted_negative\n",
    "    false_negative = positive - negative\n",
    "    true_negative = negative - false_positive\n",
    "      \n",
    "    precision = predicted_negative / predicted_positive\n",
    "    recall = predicted_negative / positive\n",
    "    \n",
    "    score = 2 * precision * recall / (precision + recall) \n",
    "    \n",
    "    if confusion_matrix:\n",
    "        print('\\nconfusion matrix')\n",
    "        print('----------------')\n",
    "        print( 'tn:{:6d} fp:{:6d}'.format(true_negative, false_positive))\n",
    "        print( 'fn:{:6d} tp:{:6d}'.format(false_negative, predicted_negative))\n",
    "    \n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    defining a function for training with given fixed and variable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(current_choice, parameters, train_X, train_S, train_y, valid_X, valid_S, valid_y, confusion_matrix = False):\n",
    "    \n",
    "    print('Parameters:')\n",
    "    for (key,value) in current_choice.items():\n",
    "        print(key,': ',value,' ',end='')\n",
    "        parameters[key]=value\n",
    "    print('\\n')    \n",
    "\n",
    "    model = xgb.train(parameters, train_X, num_boost_round = number_of_rounds)  \n",
    "    \n",
    "    predictions = model.predict(valid_X)\n",
    "    labels = valid_X.get_label()\n",
    "      \n",
    "    score = performance(predictions, labels, confusion_matrix)\n",
    "    \n",
    "    return(score, model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    defining a function choice with already assigned parameters or with random ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice(current_parameters = None):\n",
    "    \n",
    "    if current_parameters:\n",
    "        \n",
    "        choose_parameter_name, current_value = random.choice(list(current_choice.items()))\n",
    "       \n",
    "        all_values =  list(parameters_dict[choose_parameter_name])\n",
    "        current_index = all_values.index(current_value)\n",
    "        \n",
    "        if current_index == 0:\n",
    "            next_index = 1\n",
    "        elif current_index == len(all_values) - 1:\n",
    "            next_index = len(all_values) - 2\n",
    "        else:\n",
    "            direction = np.random.choice([-1, 1])\n",
    "            next_index = current_index + direction\n",
    "\n",
    "        next_parameters = dict((k,v) for k,v in current_parameters.items())\n",
    "        next_parameters[choose_parameter_name] = all_values[next_index]\n",
    "        print('selected move: {:10s}: from {:6.2f} to {:6.2f}'.\n",
    "              format(choose_parameter_name, current_value, all_values[next_index]))\n",
    "    else:\n",
    "        next_parameters = dict()\n",
    "        for i in range(len(parameters_dict)):\n",
    "            key = [*parameters_dict.keys()][i] \n",
    "            values = [*parameters_dict.values()][i]\n",
    "            next_parameters[key] = np.random.choice(values)\n",
    "    return(next_parameters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    time should be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration =     0  T =     0.400000\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  5  subsample :  0.9  eta :  0.3  colsample_bytree :  0.8  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.58  previous:  -1.00  best so far:  -1.00\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =     1  T =     0.340000\n",
      "selected move: gamma     : from   0.05 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  5  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.58  previous:   0.58  best so far:   0.58\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.2677 -> accepted\n",
      "\n",
      "Iteration =     2  T =     0.340000\n",
      "selected move: colsample_bytree: from   0.80 to   0.90\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  5  subsample :  0.9  eta :  0.3  colsample_bytree :  0.9  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.60  previous:   0.58  best so far:   0.58\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =     3  T =     0.340000\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.10 to   0.15\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  5  subsample :  0.9  colsample_bytree :  0.9  eta :  0.3  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.60  previous:   0.60  best so far:   0.60\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.8385 -> accepted\n",
      "\n",
      "Iteration =     4  T =     0.340000\n",
      "selected move: gamma     : from   0.15 to   0.10\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.30 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  5  subsample :  0.9  eta :  0.2  colsample_bytree :  0.9  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.52  previous:   0.60  best so far:   0.60\n",
      "    Worse result. Score change:  -0.0856  threshold: 0.7210  random number: 0.5362 -> accepted\n",
      "\n",
      "Iteration =     5  T =     0.340000\n",
      "selected move: subsample : from   0.90 to   1.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: subsample : from   1.00 to   0.90\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.15 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  5  subsample :  0.9  colsample_bytree :  0.9  eta :  0.2  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.52  previous:   0.52  best so far:   0.60\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.1597 -> accepted\n",
      "\n",
      "Iteration =     6  T =     0.289000\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: colsample_bytree: from   0.90 to   0.80\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  5  subsample :  0.9  eta :  0.2  colsample_bytree :  0.8  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.50  previous:   0.52  best so far:   0.60\n",
      "    Worse result. Score change:  -0.0143  threshold: 0.9379  random number: 0.3338 -> accepted\n",
      "\n",
      "Iteration =     7  T =     0.289000\n",
      "selected move: max_depth : from   5.00 to  10.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  10  subsample :  0.9  colsample_bytree :  0.8  eta :  0.2  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.79  previous:   0.50  best so far:   0.60\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =     8  T =     0.289000\n",
      "selected move: max_depth : from  10.00 to   5.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.10 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  10  subsample :  0.9  eta :  0.2  colsample_bytree :  0.8  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.79  previous:   0.79  best so far:   0.79\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.9059 -> accepted\n",
      "\n",
      "Iteration =     9  T =     0.289000\n",
      "selected move: gamma     : from   0.05 to   0.10\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.20 to   0.30\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  10  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.81  previous:   0.79  best so far:   0.79\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    10  T =     0.289000\n",
      "selected move: colsample_bytree: from   0.80 to   0.70\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  10  subsample :  0.9  eta :  0.3  colsample_bytree :  0.7  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.81  best so far:   0.81\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    11  T =     0.245650\n",
      "selected move: gamma     : from   0.05 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  10  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  scale_pos_weight :  700  \n",
      "\n",
      "    F-Score:   0.82  previous:   0.83  best so far:   0.83\n",
      "    Worse result. Score change:  -0.0027  threshold: 0.9856  random number: 0.0066 -> accepted\n",
      "\n",
      "Iteration =    12  T =     0.245650\n",
      "selected move: scale_pos_weight: from 700.00 to 600.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  10  subsample :  0.9  eta :  0.3  colsample_bytree :  0.7  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.79  previous:   0.82  best so far:   0.83\n",
      "    Worse result. Score change:  -0.0292  threshold: 0.8567  random number: 0.4483 -> accepted\n",
      "\n",
      "Iteration =    13  T =     0.245650\n",
      "selected move: gamma     : from   0.10 to   0.15\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  10  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.79  previous:   0.79  best so far:   0.83\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.0928 -> accepted\n",
      "\n",
      "Iteration =    14  T =     0.245650\n",
      "selected move: max_depth : from  10.00 to  15.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  15  subsample :  0.9  eta :  0.3  colsample_bytree :  0.7  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.79  best so far:   0.83\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    15  T =     0.245650\n",
      "selected move: max_depth : from  15.00 to  20.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.83  best so far:   0.83\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    16  T =     0.208803\n",
      "selected move: gamma     : from   0.15 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.2  max_depth :  20  subsample :  0.9  eta :  0.3  colsample_bytree :  0.7  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.84\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.2918 -> accepted\n",
      "\n",
      "Iteration =    17  T =     0.208803\n",
      "selected move: eta       : from   0.30 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.2  max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.2  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.84\n",
      "    Worse result. Score change:  -0.0046  threshold: 0.9716  random number: 0.5734 -> accepted\n",
      "\n",
      "Iteration =    18  T =     0.208803\n",
      "selected move: subsample : from   0.90 to   1.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.20 to   0.30\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.20 to   0.15\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.7  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.84\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.7688 -> accepted\n",
      "\n",
      "Iteration =    19  T =     0.208803\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.20 to   0.30\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: colsample_bytree: from   0.70 to   0.60\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.2  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.84  best so far:   0.84\n",
      "    Worse result. Score change:  -0.0107  threshold: 0.9354  random number: 0.2069 -> accepted\n",
      "\n",
      "Iteration =    20  T =     0.208803\n",
      "selected move: eta       : from   0.20 to   0.30\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  eta :  0.3  colsample_bytree :  0.6  scale_pos_weight :  600  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    F-Score:   0.84  previous:   0.83  best so far:   0.84\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    21  T =     0.177482\n",
      "selected move: scale_pos_weight: from 600.00 to 500.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.84  best so far:   0.84\n",
      "    Worse result. Score change:  -0.0136  threshold: 0.9051  random number: 0.5271 -> accepted\n",
      "\n",
      "Iteration =    22  T =     0.177482\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.15 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.3  colsample_bytree :  0.6  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.84\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.3982 -> accepted\n",
      "\n",
      "Iteration =    23  T =     0.177482\n",
      "selected move: scale_pos_weight: from 500.00 to 600.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.83  best so far:   0.84\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    24  T =     0.177482\n",
      "selected move: eta       : from   0.30 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.6  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.84  best so far:   0.84\n",
      "    Worse result. Score change:  -0.0164  threshold: 0.8867  random number: 0.4344 -> accepted\n",
      "\n",
      "Iteration =    25  T =     0.177482\n",
      "selected move: colsample_bytree: from   0.60 to   0.70\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.2  scale_pos_weight :  600  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.83  best so far:   0.84\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    26  T =     0.150860\n",
      "selected move: scale_pos_weight: from 600.00 to 500.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.7  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.84\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.7965 -> accepted\n",
      "\n",
      "Iteration =    27  T =     0.150860\n",
      "selected move: colsample_bytree: from   0.70 to   0.60\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.2  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.84  best so far:   0.84\n",
      "    Worse result. Score change:  -0.0039  threshold: 0.9666  random number: 0.8901 -> accepted\n",
      "\n",
      "Iteration =    28  T =     0.150860\n",
      "selected move: colsample_bytree: from   0.60 to   0.50\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.5  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.84\n",
      "    Worse result. Score change:  -0.0028  threshold: 0.9760  random number: 0.5206 -> accepted\n",
      "\n",
      "Iteration =    29  T =     0.150860\n",
      "selected move: eta       : from   0.20 to   0.30\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.5  eta :  0.3  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.84\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.3745 -> accepted\n",
      "\n",
      "Iteration =    30  T =     0.150860\n",
      "selected move: gamma     : from   0.10 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  eta :  0.3  colsample_bytree :  0.5  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.84\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.8473 -> accepted\n",
      "\n",
      "Iteration =    31  T =     0.128231\n",
      "selected move: scale_pos_weight: from 500.00 to 400.00\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  colsample_bytree :  0.5  eta :  0.3  scale_pos_weight :  400  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.84\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    32  T =     0.128231\n",
      "selected move: max_depth : from  20.00 to  15.00\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  15  subsample :  0.9  eta :  0.3  colsample_bytree :  0.5  scale_pos_weight :  400  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.84\n",
      "    Worse result. Score change:  -0.0039  threshold: 0.9609  random number: 0.7258 -> accepted\n",
      "\n",
      "Iteration =    33  T =     0.128231\n",
      "selected move: gamma     : from   0.05 to   0.00\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  15  subsample :  0.9  colsample_bytree :  0.5  eta :  0.3  scale_pos_weight :  400  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.84\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.9136 -> accepted\n",
      "\n",
      "Iteration =    34  T =     0.128231\n",
      "selected move: scale_pos_weight: from 400.00 to 300.00\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  15  subsample :  0.9  eta :  0.3  colsample_bytree :  0.5  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.83  best so far:   0.84\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    35  T =     0.128231\n",
      "selected move: subsample : from   0.90 to   1.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: max_depth : from  15.00 to  20.00\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  20  subsample :  0.9  colsample_bytree :  0.5  eta :  0.3  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.85  best so far:   0.85\n",
      "    Worse result. Score change:  -0.0068  threshold: 0.9331  random number: 0.3349 -> accepted\n",
      "\n",
      "Iteration =    36  T =     0.108996\n",
      "selected move: eta       : from   0.30 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.5  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.84  best so far:   0.85\n",
      "    Worse result. Score change:  -0.0085  threshold: 0.9035  random number: 0.3912 -> accepted\n",
      "\n",
      "Iteration =    37  T =     0.108996\n",
      "selected move: gamma     : from   0.00 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  colsample_bytree :  0.5  eta :  0.2  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.85\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.7231 -> accepted\n",
      "\n",
      "Iteration =    38  T =     0.108996\n",
      "selected move: colsample_bytree: from   0.50 to   0.60\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.6  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.85\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    39  T =     0.108996\n",
      "selected move: colsample_bytree: from   0.60 to   0.50\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: subsample : from   0.90 to   1.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.05 to   0.00\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.2  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.85\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.1891 -> accepted\n",
      "\n",
      "Iteration =    40  T =     0.108996\n",
      "selected move: gamma     : from   0.00 to   0.05\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: scale_pos_weight: from 300.00 to  50.00\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.6  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.85\n",
      "    Worse result. Score change:  -0.0018  threshold: 0.9792  random number: 0.3635 -> accepted\n",
      "\n",
      "Iteration =    41  T =     0.092647\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: max_depth : from  20.00 to  25.00\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  25  subsample :  0.9  colsample_bytree :  0.6  eta :  0.2  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.83  best so far:   0.85\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    42  T =     0.092647\n",
      "selected move: colsample_bytree: from   0.60 to   0.70\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  25  subsample :  0.9  eta :  0.2  colsample_bytree :  0.7  scale_pos_weight :  50  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    F-Score:   0.84  previous:   0.84  best so far:   0.85\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    43  T =     0.092647\n",
      "selected move: colsample_bytree: from   0.70 to   0.80\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.2  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.86  previous:   0.84  best so far:   0.85\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    44  T =     0.092647\n",
      "selected move: eta       : from   0.20 to   0.30\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  25  subsample :  0.9  eta :  0.3  colsample_bytree :  0.8  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.86  previous:   0.86  best so far:   0.86\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    45  T =     0.092647\n",
      "selected move: scale_pos_weight: from  50.00 to  40.00\n",
      "Parameters:\n",
      "gamma :  0.0  max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.3  scale_pos_weight :  40  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.86  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0090  threshold: 0.8816  random number: 0.8241 -> accepted\n",
      "\n",
      "Iteration =    46  T =     0.078750\n",
      "selected move: gamma     : from   0.00 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  25  subsample :  0.9  eta :  0.3  colsample_bytree :  0.8  scale_pos_weight :  40  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0099  threshold: 0.8493  random number: 0.6388 -> accepted\n",
      "\n",
      "Iteration =    47  T =     0.078750\n",
      "selected move: eta       : from   0.30 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.2  scale_pos_weight :  40  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    48  T =     0.078750\n",
      "selected move: scale_pos_weight: from  40.00 to  50.00\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  25  subsample :  0.9  eta :  0.2  colsample_bytree :  0.8  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.86  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    49  T =     0.078750\n",
      "selected move: scale_pos_weight: from  50.00 to  40.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: max_depth : from  25.00 to  20.00\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.2  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.86  previous:   0.86  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.5442 -> accepted\n",
      "\n",
      "Iteration =    50  T =     0.078750\n",
      "selected move: max_depth : from  20.00 to  25.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: max_depth : from  25.00 to  20.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: colsample_bytree: from   0.80 to   0.70\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.7  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.86  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0097  threshold: 0.8517  random number: 0.4445 -> accepted\n",
      "\n",
      "Iteration =    51  T =     0.066937\n",
      "selected move: eta       : from   0.20 to   0.30\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    52  T =     0.066937\n",
      "selected move: gamma     : from   0.05 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.3  colsample_bytree :  0.7  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.0102 -> accepted\n",
      "\n",
      "Iteration =    53  T =     0.066937\n",
      "selected move: eta       : from   0.30 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.2  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0067  threshold: 0.8775  random number: 0.1932 -> accepted\n",
      "\n",
      "Iteration =    54  T =     0.066937\n",
      "selected move: subsample : from   0.90 to   1.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: subsample : from   1.00 to   0.90\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: scale_pos_weight: from  50.00 to 300.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.7  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0125  threshold: 0.7842  random number: 0.2719 -> accepted\n",
      "\n",
      "Iteration =    55  T =     0.066937\n",
      "selected move: eta       : from   0.20 to   0.30\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.3  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.83  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    56  T =     0.056897\n",
      "selected move: scale_pos_weight: from 300.00 to  50.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.30 to   0.40\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.4  colsample_bytree :  0.7  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0058  threshold: 0.8752  random number: 0.0004 -> accepted\n",
      "\n",
      "Iteration =    57  T =     0.056897\n",
      "selected move: colsample_bytree: from   0.70 to   0.60\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.4  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    58  T =     0.056897\n",
      "selected move: gamma     : from   0.10 to   0.15\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  eta :  0.4  colsample_bytree :  0.6  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.5103 -> accepted\n",
      "\n",
      "Iteration =    59  T =     0.056897\n",
      "selected move: scale_pos_weight: from 300.00 to  50.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.4  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0072  threshold: 0.8481  random number: 0.0888 -> accepted\n",
      "\n",
      "Iteration =    60  T =     0.056897\n",
      "selected move: colsample_bytree: from   0.60 to   0.50\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  eta :  0.4  colsample_bytree :  0.5  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    61  T =     0.048362\n",
      "selected move: gamma     : from   0.15 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.5  eta :  0.4  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.86  previous:   0.85  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    62  T =     0.048362\n",
      "selected move: eta       : from   0.40 to   0.30\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.3  colsample_bytree :  0.5  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.86  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0020  threshold: 0.9483  random number: 0.3775 -> accepted\n",
      "\n",
      "Iteration =    63  T =     0.048362\n",
      "selected move: colsample_bytree: from   0.50 to   0.60\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.3  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0168  threshold: 0.6367  random number: 0.6942 -> rejected\n",
      "\n",
      "Iteration =    64  T =     0.048362\n",
      "selected move: colsample_bytree: from   0.60 to   0.50\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.10 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  colsample_bytree :  0.5  eta :  0.3  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0030  threshold: 0.9236  random number: 0.9853 -> rejected\n",
      "\n",
      "Iteration =    65  T =     0.048362\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: colsample_bytree: from   0.50 to   0.60\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.10 to   0.05\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.30 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.5  eta :  0.2  scale_pos_weight :  50  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    F-Score:   0.84  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0117  threshold: 0.7301  random number: 0.3348 -> accepted\n",
      "\n",
      "Iteration =    66  T =     0.041108\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.10 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.5  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.6391 -> accepted\n",
      "\n",
      "Iteration =    67  T =     0.041108\n",
      "selected move: max_depth : from  20.00 to  15.00\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  15  subsample :  0.9  colsample_bytree :  0.5  eta :  0.2  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.8839 -> accepted\n",
      "\n",
      "Iteration =    68  T =     0.041108\n",
      "selected move: colsample_bytree: from   0.50 to   0.60\n",
      "Parameters:\n",
      "gamma :  0.05  max_depth :  15  subsample :  0.9  eta :  0.2  colsample_bytree :  0.6  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    69  T =     0.041108\n",
      "selected move: gamma     : from   0.05 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.2  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.7177 -> accepted\n",
      "\n",
      "Iteration =    70  T =     0.041108\n",
      "selected move: scale_pos_weight: from  50.00 to  40.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  15  subsample :  0.9  eta :  0.2  colsample_bytree :  0.6  scale_pos_weight :  40  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0137  threshold: 0.6475  random number: 0.1440 -> accepted\n",
      "\n",
      "Iteration =    71  T =     0.034942\n",
      "selected move: scale_pos_weight: from  40.00 to  30.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  15  subsample :  0.9  colsample_bytree :  0.6  eta :  0.2  scale_pos_weight :  30  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.83  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    72  T =     0.034942\n",
      "selected move: max_depth : from  15.00 to  20.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.6  scale_pos_weight :  30  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    73  T =     0.034942\n",
      "selected move: scale_pos_weight: from  30.00 to  40.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.6  eta :  0.2  scale_pos_weight :  40  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0138  threshold: 0.5975  random number: 0.0784 -> accepted\n",
      "\n",
      "Iteration =    74  T =     0.034942\n",
      "selected move: scale_pos_weight: from  40.00 to  50.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.2  colsample_bytree :  0.6  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0018  threshold: 0.9368  random number: 0.0572 -> accepted\n",
      "\n",
      "Iteration =    75  T =     0.034942\n",
      "selected move: colsample_bytree: from   0.60 to   0.70\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: colsample_bytree: from   0.70 to   0.80\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.2  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.86  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "    Global improvement - best score updated\n",
      "\n",
      "Iteration =    76  T =     0.029700\n",
      "selected move: eta       : from   0.20 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.1  colsample_bytree :  0.8  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.86  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0251  threshold: 0.3330  random number: 0.3062 -> accepted\n",
      "\n",
      "Iteration =    77  T =     0.029700\n",
      "selected move: scale_pos_weight: from  50.00 to 300.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.1  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    78  T =     0.029700\n",
      "selected move: subsample : from   0.90 to   1.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.10 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.05  colsample_bytree :  0.8  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.82  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0113  threshold: 0.6100  random number: 0.3685 -> accepted\n",
      "\n",
      "Iteration =    79  T =     0.029700\n",
      "selected move: colsample_bytree: from   0.80 to   0.90\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.05  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.82  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    80  T =     0.029700\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: colsample_bytree: from   0.90 to   1.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.05  colsample_bytree :  1  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.82  previous:   0.83  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0111  threshold: 0.6141  random number: 0.1196 -> accepted\n",
      "\n",
      "Iteration =    81  T =     0.025245\n",
      "selected move: max_depth : from  20.00 to  15.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  15  subsample :  0.9  colsample_bytree :  1  eta :  0.05  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.79  previous:   0.82  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0240  threshold: 0.2905  random number: 0.8023 -> rejected\n",
      "\n",
      "Iteration =    82  T =     0.025245\n",
      "selected move: colsample_bytree: from   1.00 to   0.90\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: colsample_bytree: from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.10 to   0.15\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  1  eta :  0.05  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.82  previous:   0.82  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.7414 -> accepted\n",
      "\n",
      "Iteration =    83  T =     0.025245\n",
      "selected move: colsample_bytree: from   1.00 to   0.90\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  eta :  0.05  colsample_bytree :  0.9  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.82  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    84  T =     0.025245\n",
      "selected move: scale_pos_weight: from 300.00 to  50.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.9  eta :  0.05  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.82  previous:   0.83  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0115  threshold: 0.5545  random number: 0.0206 -> accepted\n",
      "\n",
      "Iteration =    85  T =     0.025245\n",
      "selected move: colsample_bytree: from   0.90 to   0.80\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  eta :  0.05  colsample_bytree :  0.8  scale_pos_weight :  50  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.82  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    86  T =     0.021459\n",
      "selected move: scale_pos_weight: from  50.00 to 300.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.05  scale_pos_weight :  300  \n",
      "\n",
      "    F-Score:   0.82  previous:   0.83  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0051  threshold: 0.7339  random number: 0.7402 -> rejected\n",
      "\n",
      "Iteration =    87  T =     0.021459\n",
      "selected move: scale_pos_weight: from 300.00 to 400.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.05  scale_pos_weight :  400  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.83  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    88  T =     0.021459\n",
      "selected move: scale_pos_weight: from 400.00 to 500.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  eta :  0.05  colsample_bytree :  0.8  scale_pos_weight :  500  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    F-Score:   0.83  previous:   0.83  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0057  threshold: 0.7090  random number: 0.4511 -> accepted\n",
      "\n",
      "Iteration =    89  T =     0.021459\n",
      "selected move: eta       : from   0.05 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.1  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.83  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    90  T =     0.021459\n",
      "selected move: gamma     : from   0.15 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.1  colsample_bytree :  0.8  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.1586 -> accepted\n",
      "\n",
      "Iteration =    91  T =     0.018240\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.10 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.05  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.83  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:  -0.0114  threshold: 0.4427  random number: 0.5147 -> rejected\n",
      "\n",
      "Iteration =    92  T =     0.018240\n",
      "selected move: max_depth : from  20.00 to  25.00\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  25  subsample :  0.9  colsample_bytree :  0.8  eta :  0.1  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    93  T =     0.018240\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: colsample_bytree: from   0.80 to   0.70\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  25  subsample :  0.9  eta :  0.1  colsample_bytree :  0.7  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    94  T =     0.018240\n",
      "selected move: gamma     : from   0.10 to   0.15\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  25  subsample :  0.9  colsample_bytree :  0.7  eta :  0.1  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.5455 -> accepted\n",
      "\n",
      "Iteration =    95  T =     0.018240\n",
      "selected move: subsample : from   0.90 to   0.80\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: max_depth : from  25.00 to  20.00\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  eta :  0.1  colsample_bytree :  0.7  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.8934 -> accepted\n",
      "\n",
      "Iteration =    96  T =     0.015504\n",
      "selected move: subsample : from   0.90 to   1.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: gamma     : from   0.15 to   0.10\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.1  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.84  previous:   0.84  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.2718 -> accepted\n",
      "\n",
      "Iteration =    97  T =     0.015504\n",
      "selected move: eta       : from   0.10 to   0.20\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: max_depth : from  20.00 to  25.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: max_depth : from  25.00 to  20.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: subsample : from   0.90 to   1.00\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: subsample : from   1.00 to   0.90\n",
      "\n",
      "Combination revisited - searching again\n",
      "selected move: eta       : from   0.10 to   0.05\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  eta :  0.05  colsample_bytree :  0.7  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.84  best so far:   0.86\n",
      "    Local improvement\n",
      "\n",
      "Iteration =    98  T =     0.015504\n",
      "selected move: gamma     : from   0.10 to   0.15\n",
      "Parameters:\n",
      "gamma :  0.15  max_depth :  20  subsample :  0.9  colsample_bytree :  0.7  eta :  0.05  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.9383 -> accepted\n",
      "\n",
      "Iteration =    99  T =     0.015504\n",
      "selected move: gamma     : from   0.15 to   0.20\n",
      "Parameters:\n",
      "gamma :  0.2  max_depth :  20  subsample :  0.9  eta :  0.05  colsample_bytree :  0.7  scale_pos_weight :  500  \n",
      "\n",
      "    F-Score:   0.85  previous:   0.85  best so far:   0.86\n",
      "    Worse result. Score change:   0.0000  threshold: 1.0000  random number: 0.9561 -> accepted\n",
      "\n",
      "  14.1 minutes process time\n",
      "\n",
      "Best variable parameters found:\n",
      "\n",
      "{'gamma': 0.1, 'max_depth': 20, 'subsample': 0.90000000000000002, 'colsample_bytree': 0.8, 'eta': 0.2, 'scale_pos_weight': 50}\n"
     ]
    }
   ],
   "source": [
    "t0 = time.clock()\n",
    "\n",
    "T = 0.40\n",
    "\n",
    "best_parameters = {}\n",
    "\n",
    "best_score = -1. \n",
    "last_score = -1. \n",
    "last_choice = None\n",
    "weights = list(map(lambda x: 10 ** x, [0, 1, 2, 3, 4]))\n",
    "hash_values = set()\n",
    "\n",
    "for iter in range(maximum_iterations):\n",
    "    print('\\nIteration = {:5d}  T = {:12.6f}'.format(iter,T))\n",
    "    \n",
    "    while True:\n",
    "        current_choice = choice(last_choice)\n",
    "         \n",
    "        indices=[parameters_dict[name].index(current_choice[name]) for name in sorted([*parameters_dict.keys()])]\n",
    "\n",
    "        hash_value = sum([i * j for (i, j) in zip(weights, indices)])\n",
    "        if hash_value in hash_values:\n",
    "            print('\\nCombination revisited - searching again')\n",
    "            \n",
    "        else:\n",
    "            hash_values.add(hash_value)\n",
    "            break\n",
    "    \n",
    "    \n",
    "    score, model = train(current_choice, parameters, fixed_train, 'train', train_y, fixed_validation, 'valid', validation_y)\n",
    "    \n",
    "    results.loc[iter,[*current_choice.keys()]] = list(current_choice.values())\n",
    "    \n",
    "    print('    F-Score: {:6.2f}  previous: {:6.2f}  best so far: {:6.2f}'.format(score, last_score, best_score))\n",
    " \n",
    "    if score > last_score:\n",
    "        print('    Local improvement')\n",
    "        \n",
    "        last_score = score\n",
    "        last_choice = current_choice\n",
    "        \n",
    "        if score > best_score:\n",
    "            \n",
    "            best_score = score\n",
    "            print('    Global improvement - best score updated')\n",
    "            for (key,value) in last_choice.items():\n",
    "                best_parameters[key] = value\n",
    "\n",
    "    else:\n",
    "        \n",
    "        random_f = random.random()\n",
    "        difference = score - last_score\n",
    "        threshold = np.exp(1.3 * difference / T)\n",
    "        if random_f <= threshold:\n",
    "            print('    Worse result. Score change: {:8.4f}  threshold: {:6.4f}  random number: {:6.4f} -> accepted'.\n",
    "                  format(difference, threshold, random_f))\n",
    "            last_score = score\n",
    "            last_choice = current_choice\n",
    " \n",
    "        else:\n",
    "            print('    Worse result. Score change: {:8.4f}  threshold: {:6.4f}  random number: {:6.4f} -> rejected'.\n",
    "                 format(difference, threshold, random_f))\n",
    "    results.loc[iter,'Score'] = score\n",
    "    results.loc[iter,'Best Score'] = best_score\n",
    "    if iter % 5 == 0: T = 0.85 * T  \n",
    "        \n",
    "print('\\n{:6.1f} minutes process time\\n'.format((time.clock() - t0)/60))    \n",
    "\n",
    "print('Best variable parameters found:\\n')\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "\n",
      "{'gamma': 0.1, 'max_depth': 20, 'subsample': 0.90000000000000002, 'colsample_bytree': 0.8, 'eta': 0.2, 'scale_pos_weight': 50}\n",
      "\n",
      "Evaluation on the test dataset\n",
      "\n",
      "Parameters:\n",
      "gamma :  0.1  max_depth :  20  subsample :  0.9  colsample_bytree :  0.8  eta :  0.2  scale_pos_weight :  50  \n",
      "\n",
      "\n",
      "confusion matrix\n",
      "----------------\n",
      "tn: 85275 fp:    15\n",
      "fn:-85138 tp:   131\n",
      "\n",
      "Score on the test dataset:   0.88\n"
     ]
    }
   ],
   "source": [
    "print('\\nBest parameters found:\\n')  \n",
    "print(best_parameters)\n",
    "\n",
    "print('\\nEvaluation on the test dataset\\n')  \n",
    "\n",
    "best_score, best_model = train(best_parameters, parameters, fixed_train, 'train', train_y, fixed_test, 'test', test_y, confusion_matrix = True)\n",
    "\n",
    "\n",
    "print('\\nScore on the test dataset: {:6.2f}'.format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = xgb.plot_importance(best_model) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
